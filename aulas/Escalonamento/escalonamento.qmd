---
title: "Escalonamento Multidimensional"
format: 
  revealjs:
    width: 1600
    height: 900
    footer: ""
    theme: quartomonothemer.scss
    slide-number: c/t
    show-slide-number: all
    preview-links: auto
    self-contained: true
incremental: false
code-link: true
bibliography: references.bib
title-slide-attributes:
    data-background-image: /images/back.jpeg
    data-background-size: cover
    data-background-opacity: "0.3"
execute:
  echo: true
---


## Motivação

<br>

> "Nem sempre conseguimos enxergar padrões com os olhos. Às vezes, precisamos de matemática para revelá-los."

. . .

Imagine tentar entender as preferências de centenas de pessoas, ou visualizar a semelhança entre dezenas de produtos. Como representar isso de forma intuitiva?










## Exemplo prático

Uma empresa de telefonia realizou uma pesquisa para avaliar como os clientes percebiam diferentes marcas concorrentes no mercado. Cada entrevistado avaliou o grau de similaridade entre as marcas, sem indicar explicitamente o motivo. Com esses dados, aplicou-se MDS para construir um mapa perceptual.

:::: {.columns}

::: {.column width="50%"}

![](/images/mds_telefonia.png){.nostretch fig-align="center" width="700px"}
:::

::: {.column width="50%" .fragment}

- Claro e Vivo estão próximas, sugerindo que os consumidores as percebem como similares.

- TIM e Oi também aparecem próximas, formando um outro grupo perceptual.

- Nextel está mais distante das demais, indicando uma percepção diferenciada.

:::

::::


## O que é MDS? 

**Escalonamento Multidimensional (MDS)** é uma técnica exploratória de redução de dimensionalidade baseada em distâncias ou dissimilaridades.

. . .


**Objetivo:** encontrar uma representação espacial dos objetos em *k* dimensões, preservando as distâncias originais tanto quanto possível.


. . .

<span style='font-size:50px;'>&#129300;</span> Diferente do PCA, que usa variância, o MDS parte de uma **matriz de distâncias**.

. . .

MDS pode ser utilizado com ou sem os dados originais, desde que se conheça a matriz de distância.


## Formulação matemática

Dada uma matriz de distâncias $\Delta = (\delta_{ij})_{n \times n}$, o **objetivo do escalonamento multidimensional** é encontrar 
pontos $P_1, P_2, \cdots, P_n$, $k$-dimensionais tais que, se $d_{ij}$ denota a distância euclidiana entre $P_i$ e $P_j$, então $D = (d_{ij})$ é "próxima"
a $\Delta$ em algum sentido.

. . .

- **Métodos métricos:** os pontos $P$ são obtidos de tal forma que $D \approx \Delta$
    - Assume distâncias reais, preservando as magnitudes.

. . .


- **Métodos não métricos:** baseados na ordenação das $\displaystyle{\frac{n(n-1)}{2}}$ distâncias
    - Assume apenas a ordem das distâncias.


## Formulação matemática: MDS métrico

<br>

- Considere a matriz $\Delta = (\delta_{ij})$ das distâncias originais entre os $n$ indivíduos.

. . .

- Nosso objetivo é encontrar $n$ pontos $k$-dimensionais de tal forma que a distância $d_{ij}$ entre os indivíduos $i$ e $j$ em 
$k$ dimensões seja aproximadamente igual ao valor de $\delta_{ij}$ em $\Delta$. 

. . .

- Geralmente, temos $k=2$ ou $k=3$.



## Formulação matemática: MDS métrico

<br>

- Para encontrar os pontos $P_1, P_2, \cdots, P_n$:
  a) Encontrar uma matriz $A_n = (a_{ij})$, onde $a_{ij} = -\displaystyle{\frac{1}{2}} \delta_{ij}^2$, sendo $\delta_{ij}$ o $ij$-ésimo elemento de $\Delta$
  b) Construir a matriz $B = (b_{ij})$, onde $b_{ij} = a_{ij} - \bar{a}_{i\cdot} - \bar{a}_{\cdot j} + \bar{a}_{\cdot \cdot}$, em que

$$\bar{a}_{i\cdot} = \displaystyle{\frac{\displaystyle{\sum_{j = 1}^n} a_{ij}}{n}},  \hspace{0.5cm}
\bar{a}_{\cdot j} = \displaystyle{\frac{\displaystyle{\sum_{i = 1}^n} a_{ij}}{n}}  \hspace{0.25cm} \text{e} \hspace{0.25cm}
\bar{a}_{\cdot \cdot} = \displaystyle{\frac{\displaystyle{\sum_{i = 1}^n} \displaystyle{\sum_{j = 1}^n} a_{ij}}{n}} $$


## Formulação matemática: MDS métrico


A matriz $B$ pode ser escrita na forma matricial:

$$B = \left ( \mathrm{I}-\frac{1}{n}\mathrm{J}\right )A\left ( \mathrm{I}-\frac{1}{n}\mathrm{J}\right )$$

  c) Uma vez que $B$ é simétrica, podemos encontrar a decomposição espectral da matriz $B$:

$$B = O \Lambda O^{t}$$

em que $O$ é a matriz de autovetores normalizados e $\Lambda$ é a matriz diagonal dos autovalores de $B$.


## Formulação matemática: MDS métrico

- **Observação:** Se $B$ é positiva semidefinida de posto $q$, então existem $q$ autovalores positivos e os $(n-q)$ 
autovalores iguais a zero. Sejam $\Lambda_{1} = \text{diag}(\lambda_{1},\lambda_{2}, \cdots, \lambda_{q})$ a matriz diagonal com os $q$ 
autovalores positivos e $O_{1}=(\mathbf{e}_{1},\mathbf{e}_{2}, \cdots, \mathbf{e}_{q})$ a matriz com os correspondente autovetores 
normalizados.

. . .

- Assim, podemos reescrever,

$$\begin{eqnarray*}
B &=& O_{1}\Lambda_{1}O_{1}^{t} \\
&=& O_{1}\Lambda_{1}^{\frac{1}{2}}\Delta_{1}^{\frac{1}{2}}O_{1}^{t} \\
&=& ZZ^{t}
\end{eqnarray*} $$


## Formulação matemática: MDS métrico

em que

$$
\begin{eqnarray}
Z=O_{1}\Lambda_{1}^{\frac{1}{2}}=(\sqrt{\lambda_{1}}\mathbf{e}_{1}, \sqrt{\lambda_{2}}\mathbf{e}_{2}, \cdots, \sqrt{\lambda_{q}}\mathbf{e}_{q})=\begin{pmatrix}
\mathbf{Z}_{1}^{t}\\ \mathbf{Z}_{2}^{t}\\ \vdots\\ \mathbf{Z}_{n}^{t}\end{pmatrix}
\end{eqnarray}
$$

## Formulação matemática: MDS métrico


  d) As linhas $\mathbf{Z}_{1}^{t}, \mathbf{Z}_{2}^{t}, \cdots, \mathbf{Z}_{n}^{t}$ são os pontos cuja distância $d_{ij} = (\mathbf{Z}_{i}-\mathbf{Z}_{j})^{t}(\mathbf{Z}_{i}-\mathbf{Z}_{j})$ corresponde às distâncias $\delta_{ij}$ da matriz de distâncias $\Delta$.

. . .

  e) Se usarmos os $q$ autovalores positivos para construir a matriz $\Lambda_{1}$, teremos $d_{ij} = \delta_{ij}$. A ideia é utilizarmos um número $k < q$ (geralmente $k = 2$ ou $k = 3$) de autovalores e autovetores correspondentes para encontrarmos $n$ pontos cujas distâncias $d_{ij}$ sejam aproximadamente iguais às correspondentes $\delta_{ij}$.

. . .

  f) Se $B$ não é positiva semidefinida, porém os $k$ primeiros autovalores são positivos, então estes podem ser usados para 
construção das matrizes $O_{1}$ e $\Lambda_{1}$.


## Exemplo 01: Distâncias entre capitais brasileiras

<br>

Os dados referem-se à matriz de distâncias empíricas entre algumas capitais brasileiras. O objetivo é encontrar uma representação
gráfica dessas capitais baseada apenas nessas distâncias.


## Exemplo 01: Distâncias entre capitais brasileiras

```{r}
D = read.table("https://raw.githubusercontent.com/tiagomartin/est022/refs/heads/main/dados/distancias_capitais.dat", header=T)
D
```



## Exemplo 01: Distâncias entre capitais brasileiras

```{r}
mds = cmdscale(D,eig=TRUE, k=2) 
mds
```

## Exemplo 01: Distâncias entre capitais brasileiras

```{r}
plot(mds$points, type = "n", main = "MDS - Capitais")
text(mds$points, labels = rownames(D), cex = 0.7)
```

## Exemplo 01: Distâncias entre capitais brasileiras

```{r}
# Refletindo a solução
mds_refletida = mds$points
mds_refletida[, 1] = -mds_refletida[, 1]
mds_refletida[, 2] = -mds_refletida[, 2]

plot(mds_refletida, type = "n", main = "MDS - Capitais")
text(mds_refletida, labels = rownames(D), cex = 0.7)
```


## MDS métrico para matriz de similaridades

Como obter as coordenadas principais $\mathbf{Z}$ a partir da matriz de similaridades?

. . .

- Seja $C = (c_{ij})$ a matriz de similaridade entre os $n$ objetos tal que,

$$c_{ij} = c_{ji}  \hspace{1cm} c_{ij} \leqslant c_{ii} \hspace{0.3cm} i,j = 1, \cdots, n$$

. . .

- Podemos obter $\Delta = (\delta_{ij})$ a partir de $C = (c_{ij})$ de acordo com:

$$\delta_{ij} = (c_{ii} + c_{jj} - 2c_{ij})^{1/2}$$

. . .

- $\Delta$ é a matriz de distâncias euclidianas  $\Longrightarrow$ obter $B$ e sua decomposição


## MDS métrico para matriz de similaridades

<br>

Alternativamente...

. . .

$$B = \left ( \mathrm{I}-\frac{1}{n}\mathrm{J}\right )C\left ( \mathrm{I}-\frac{1}{n}\mathrm{J}\right )$$


. . .


Encontrar as coordenadas principais $\mathbf{Z}$ conforme visto anteriormente.


## Exemplo 02: Percepção de Marcas (Pesquisa de Marketing)

Suponha que uma empresa de pesquisa de mercado realizou entrevistas com consumidores, solicitando que avaliassem o quão similares eles acham diferentes marcas de refrigerantes. O resultado foi uma matriz de dissimilaridades baseada na percepção subjetiva dos participantes.


```{r}
#| echo: false
brands <- c("Coca-Cola", "Pepsi", "Guaraná Antarctica", "Fanta", "Sprite")
C <- matrix(c(
  5, 4, 3, 2, 2,
  4, 5, 3, 2, 3,
  3, 3, 5, 4, 4,
  2, 2, 4, 5, 5,
  2, 3, 4, 5, 5
), nrow = 5, byrow = TRUE)
dimnames(C) <- list(brands, brands)
```

```{r}
C
```


## Exemplo 02: Percepção de Marcas (Pesquisa de Marketing)

```{r}
diag_C = diag(C)
D = outer(diag_C, rep(1, nrow(C))) + outer(rep(1, nrow(C)), diag_C) - 2 * C
dimnames(D) = list(brands, brands)
D
```


## Exemplo 02: Percepção de Marcas (Pesquisa de Marketing)


```{r}
mds = cmdscale(D,eig=TRUE, k=2) 
plot(mds$points, type = "n", main = "MDS - Marcas de refrigerante")
text(mds$points, labels = rownames(D), cex = 0.7)
```


## Exemplo 02: Percepção de Marcas (Pesquisa de Marketing) 

1. Coca-Cola e Pepsi:
  - Aparecem próximas entre si e distantes das demais, especialmente no eixo horizontal. Isso sugere que os consumidores as percebem como marcas muito similares (o que é consistente com sua categoria de colas tradicionais).

. . .


2. Fanta e Sprite:
  - Estão relativamente próximas, mas não sobrepostas. Ambas localizadas no lado direito do gráfico, são percebidas como similares entre si, o que pode ser explicado por características compartilhadas: Sabores cítricos, sensação de leveza, ausência de cafeína e associação a refrescância.


## Exemplo 02: Percepção de Marcas (Pesquisa de Marketing) 

3. Guaraná Antarctica:
  - Está localizada numa posição intermediária entre colas (Coca-Cola e Pepsi) e os refrigerantes frutados (Fanta e Sprite). Isso indica que a percepção do Guaraná é distinta de ambos os grupos, sendo percebido como um produto com identidade própria, nem tão semelhante às colas, nem aos refrigerantes cítricos.

. . .

4. Distância de Fanta/Sprite para Coca-Cola/Pepsi: 
  - Reforça a ideia de que consumidores veem essas bebidas como categorias distintas, talvez associando colas a sabores mais fortes, tradição e energia, enquanto Sprite/Fanta a refrescância e informalidade.
  
  
  
## Exemplo 02: Possíveis interpretações práticas

<br>

- Sobreposição de mercado moderada entre Fanta e Sprite: embora não estejam sobrepostas, a proximidade sugere que competem por um mesmo nicho. Pode ser necessário reforçar seus atributos únicos.

. . .

- Guaraná Antarctica como “ponte perceptual” ou nicho isolado: sua posição intermediária pode representar uma oportunidade estratégica de reposicionamento como opção alternativa às categorias dominantes.

. . .

- Colas claramente delimitadas: Coca-Cola e Pepsi formam um grupo distinto e bem consolidado na mente do consumidor, o que reforça a importância de manter campanhas focadas em fidelização, legado e diferenciação sutil.





## Observações

<br>

- O MDS não atribui significado direto aos eixos (Dimensão 1 e 2), mas permite interpretar relações de proximidade.

. . .

- O importante é a distância relativa entre os pontos (marcas).


## Formulação matemática: MDS Não-métrico

-  $\Delta = (\delta_{ij})$ é considerada uma matriz de dissimilaridade geral (não precisa ser de distâncias euclidianas)

. . .

- Os elementos de $\Delta$ podem ser ordenados

$$\delta_{ij}^{(1)} \leqslant \delta_{ij}^{(2)} \leqslant \cdots \leqslant \delta_{ij}^{(m)}, \hspace{0.5cm} m = \displaystyle{\frac{n(n-1)}{2}}$$


. . .

- Seja $D = (d_{ij})$, tal que os elementos $d_{ij}$ estão monotonicamente relacionados com os elementos $\delta_{ij}$

$$\delta_{ij} < \delta_{rs} \Longrightarrow d_{ij} < d_{rs};  \hspace{0.5cm} i < j, r < s$$


## Formulação matemática: MDS Não-métrico

- Seja $Z$ uma configuração $k$-dimensional com distâncias $d_{ij}$. $Z$ é ótima no sentido de minimizar a seguinte medida:

$$
\begin{equation} S^2(Z) = \displaystyle{\frac{\displaystyle{\sum_{i < j}} (\delta_{ij} - d_{ij})^2}
 {\displaystyle{\sum_{i < j} \delta_{ij}^2}}} 
\end{equation}
$$

. . .

- O valor mínimo de $S^2$ para uma dada dimensão $k$ é chamado de STRESS (STandard REsiduals Sum of Squares). O STRESS mede o quanto
da variância das dissimilaridades NÃO é explicada pelas $k$ coordenadas principais.



## Formulação matemática: MDS Não-métrico

**Passos para encontrar o STRESS**

a) Ranquear as $m=\frac{n(n-1)}{2}$ distâncias ou dissimilaridades $\delta_{ij}$.

. . .

b)  Escolha um valor de $k$ e a configuração inicial dos pontos em $k$ dimensões. A escolha de $k$ pode seguir a seguinte regra 
prática:

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;margin:0px auto;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:38px;
  overflow:hidden;padding:20px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:38px;
  font-weight:normal;overflow:hidden;padding:20px 5px;word-break:normal;}
.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
</style>
<table class="tg"><thead>
  <tr>
    <th class="tg-c3ow">Dimensões</th>
    <th class="tg-c3ow">Indivíduos</th>
  </tr></thead>
<tbody>
  <tr>
    <td class="tg-c3ow">k = 1</td>
    <td class="tg-c3ow">pelo menos 5</td>
  </tr>
  <tr>
    <td class="tg-c3ow">k = 2</td>
    <td class="tg-c3ow">pelo menos 9</td>
  </tr>
  <tr>
    <td class="tg-c3ow">k = 3</td>
    <td class="tg-c3ow">pelo menos 13</td>
  </tr>
  <tr></tr>
</tbody>
</table>

A configuração inicial dos pontos nas $k$ dimensões pode ser tomada como a solução do MDS métrico.

## Formulação matemática: MDS Não-métrico

<br>

c) Para a configuração inicial dos pontos, encontre a distância $\delta_{ij}$ entre eles. Encontre os valores de $d_{ij}$ que minimizem a função $S^2(Z)$.

. . .

d) Escolha a nova configuração de pontos cujas distâncias $d_{ij}$ minimizam $S^{2}$.

. . .

e) Encontre novos valores de $d_{ij}$ para os valores de $\delta_{ij}$ encontrados no passo `d`. Encontre os novos valores da função STRESS.

. . .

f) Repita os passos `d` e `e` até o STRESS convergir para um valor mínimo sobre todas as possíveis $k$-dimensionais configurações dos pontos.


## Formulação matemática: MDS Não-métrico

**Regra prática:** Como avaliar os valores de STRESS?

<br>

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;margin:0px auto;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:38px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:38px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
</style>
<table class="tg"><thead>
  <tr>
    <th class="tg-0pky">Stress</th>
    <th class="tg-0pky">Ajuste</th>
  </tr></thead>
<tbody>
  <tr>
    <td class="tg-0pky">maior que 0,20</td>
    <td class="tg-0pky">Ruim</td>
  </tr>
  <tr>
    <td class="tg-0pky">entre 0,10 e 0,20</td>
    <td class="tg-0pky">Regular</td>
  </tr>
  <tr>
    <td class="tg-0pky">entre 0,05 e 0,10</td>
    <td class="tg-0pky">Bom</td>
  </tr>
  <tr>
    <td class="tg-0pky">menor que 0,05</td>
    <td class="tg-0pky">Excelente</td>
  </tr>
  <tr></tr>
</tbody>
</table>


## O gráfico Shepard

- Compara as distâncias ajustadas pelo modelo e as disparidades originais, permitindo uma análise de diagnóstico  da qualidade do 
ajuste do modelo.

. . .

- É um gráfico de dispersão, no qual se espera como resultado que os pontos não se afastem muito de uma linha crescente, indicando que cada 
dissimilaridade original, dada pela disparidade, é bem representada pela distância ajustada pelo modelo.
  - Se os pontos estão próximos da linha → **boa representação** das dissimilaridades no espaço de menor dimensão.
  - Dispersão dos pontos longe da linha → indica **stress maior** e ajuste menos fiel.


## Exemplo 03: Posicionamento de Marcas de Cerveja

- Os dados referem-se à uma pesquisa sobre o posicionamento de algumas marcas nacionais de cerveja comercializadas nos restaurantes, bares e mercados brasileiros. 

. . .

- Para o experimento, foram selecionadas 10 marcas dentre as principais cervejas fabricadas e comercializadas no Brasil.

. . .

- 20 apreciadores classificaram as marcas aos pares, atribuindo o escore 0 (caso pertençam a um mesmo grupo) ou o escore 1 (caso contrário) 

. . .

- Os escores foram agrupados. Quanto menor o escore total, mais similares são as marcas.


## Exemplo 03: Posicionamento de Marcas de Cerveja

```{r}
D = read.table("https://raw.githubusercontent.com/tiagomartin/est022/refs/heads/main/dados/cervejas_nmds.dat", header=T)
D = as.matrix(D)
D
```


## Exemplo 03: Posicionamento de Marcas de Cerveja

```{r}
library(MASS)
Nmds = isoMDS(D,y=cmdscale(D,2))
```

```{r}
#| output-location: slide
<<<<<<< HEAD
par(mar = c(4, 4, 2, 1))  
=======
par(mar = c(4, 4, 2, 1))  # margens inferiores, esquerdas, superiores, direitas
>>>>>>> a4c75c59e0626d2e54ed681bb1ed95d9b6628ae1
plot(Nmds$points, type = "n", main = "Mapa NMDS - Cervejas", xlab="", ylab="")
text(Nmds$points, labels = row.names(D), cex=.7) 
```

## Exemplo 03: Posicionamento de Marcas de Cerveja

```{r}
# Shepard Diagram
shep = Shepard(as.dist(D), Nmds$points)

# Plot usando base R
plot(shep$x, shep$y, xlab = "Dissimilaridade original",
     ylab = "Distância Euclidiana no Mapa",
     main = "Shepard Diagram (NMDS)",
     pch = 20)
lines(shep$x, shep$yf, type = "s", col = "blue")
```

## Exemplo 03: Posicionamento de Marcas de Cerveja


<br>

- Há boa aderência dos pontos à linha azul, o que sugere que o modelo NMDS capturou bem a estrutura perceptual dos dados.

. . .

- Isso valida o uso do mapa gerado para interpretações estratégicas como segmentação, diferenciação de marcas ou agrupamento perceptual.


## Exemplo 03: Posicionamento de Marcas de Cerveja

- **Grupo 1: Bohemia, Brahma Extra, Serra Malte**
    - Estão no lado esquerdo, relativamente próximos.
    - Provavelmente são percebidas como cervejas premium ou especiais.
    - Serra Malte é mais afastada verticalmente, sugerindo que é percebida como mais diferenciada, mas ainda próxima desse grupo de cervejas artesanais ou encorpadas.

. . .

- **Grupo 2: Skol, Brahma**
    - Estão próximos no centro do mapa.
    - São cervejas populares, leves, comerciais: percebidas como similares entre si e intermediárias entre os grupos.
    
    
## Exemplo 03: Posicionamento de Marcas de Cerveja

<br>

- **Grupo 3: Nova Schin, Kaiser, Itaipava, Cintra**
    - Estão no lado direito, com Nova Schin e Kaiser próximos.
    - Cervejas econômicas ou consideradas mais leves, talvez associadas a preço competitivo ou menor diferenciação de sabor.
    
. . .

- **Antarctica**
    - Isolada no canto superior direito.
    - Pode indicar percepção de sabor distinto ou perfil tradicional, com diferenciação tanto dos grupos populares quanto dos especiais.


## Exemplo 03:  Aplicações práticas

<br>

- **Posicionamento de Marca:** empresas podem identificar o espaço ocupado por suas marcas e posicioná-las estrategicamente.

. . .

- **Lançamento de produto:** um novo rótulo pode ser idealizado para ocupar um “espaço vazio” no mapa.

. . .

- **Segmentação de mercado:** os clusters refletem perfis de consumidores distintos.